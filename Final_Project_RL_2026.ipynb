{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# üéÆ Deep RL Final Project ‚Äî MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## üåç The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8√ó8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key ‚Üí Open door ‚Üí Pick up ball ‚Üí Reach goal |\n",
        "\n",
        "## ‚úÖ What You CAN Modify\n",
        "- **Preprocessing** ‚Äî Implement your own observation preprocessing function.\n",
        "- **Reward shaping** ‚Äî Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** ‚Äî Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## ‚ùå What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## üì¶ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## üß™ Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## üßæ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> ‚ö†Ô∏è **Important**\n",
        ">\n",
        "> The two environments below are **fixed**‚Äîdo not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** ‚Äî set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** ‚Äî edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: State getter methods (use these in reward shaping)   ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> üí° **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320√ó320√ó3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) ‚Äî smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    #TODO check if check use several images\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# üîç Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8√ó8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    2\n",
            "Agent position:     (3, 1)\n",
            "Goal position:      (8, 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key ‚Üí Door ‚Üí Ball ‚Üí Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key ‚Üí Open door ‚Üí Enter right room ‚Üí Pick up ball ‚Üí Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` ‚Äî True if agent has the key\n",
        "- `is_carrying_ball()` ‚Äî True if agent has the ball\n",
        "- `is_door_open()` ‚Äî True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(1), np.int64(3))\n",
            "Carrying key:    False\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# Config (hyperparameters and env-derived settings)\n",
        "# ==========================================\n",
        "class Config:\n",
        "    \"\"\"Holds agent/environment config. Pass env to fill input_shape and num_actions from it.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env=None,\n",
        "        memory_size=10_000,\n",
        "        minibatch_size=64,\n",
        "        discount_factor=0.99,\n",
        "        total_episodes=1000,\n",
        "        epsilon=1.0,\n",
        "        epsilon_ending_value=0.01,\n",
        "        epsilon_decay_value=0.995,\n",
        "        frame_skipping=1,\n",
        "        **kwargs\n",
        "    ):\n",
        "        if env is not None:\n",
        "            obs_space = env.observation_space\n",
        "            raw_shape = getattr(obs_space, \"shape\", (3, 84, 84))\n",
        "            # PyTorch Conv2d expects (C, H, W). If env gives (H, W, C), convert.\n",
        "            if len(raw_shape) == 3 and raw_shape[-1] in (1, 3):\n",
        "                self.input_shape = (raw_shape[-1], raw_shape[0], raw_shape[1])\n",
        "            else:\n",
        "                self.input_shape = raw_shape\n",
        "            self.num_actions = env.action_space.n\n",
        "        else:\n",
        "            self.input_shape = kwargs.get(\"input_shape\", (3, 84, 84))\n",
        "            self.num_actions = kwargs.get(\"num_actions\", 5)\n",
        "        self.memory_size = memory_size\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.discount_factor = discount_factor\n",
        "        # Training loop hyperparameters\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_ending_value = epsilon_ending_value\n",
        "        self.epsilon_decay_value = epsilon_decay_value\n",
        "        self.frame_skipping = frame_skipping\n",
        "\n",
        "# ==========================================\n",
        "# The Model\n",
        "# ==========================================\n",
        "class MiniGridNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, mode='value'):\n",
        "        super().__init__()\n",
        "        # input_shape must be (C, H, W) for Conv2d\n",
        "        c, h, w = input_shape[0], input_shape[1], input_shape[2]\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=16, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        # Compute conv output size so it works for any input (C, H, W)\n",
        "        def _conv_out(in_size, k, s):\n",
        "            return (in_size - k) // s + 1\n",
        "        h1, w1 = _conv_out(h, 8, 4), _conv_out(w, 8, 4)\n",
        "        h2, w2 = _conv_out(h1, 4, 2), _conv_out(w1, 4, 2)\n",
        "        flat_size = 32 * h2 * w2\n",
        "\n",
        "        self.q_head = nn.Sequential(\n",
        "            nn.Linear(flat_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.q_head(features)\n",
        "\n",
        "# ==========================================\n",
        "# THE MEMORY\n",
        "# ==========================================\n",
        "class ExperienceMemory:\n",
        "    def __init__(self, capacity, is_on_policy=False):\n",
        "        # Use GPU if available, otherwise fall back to CPU\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # Set the maximum memory capacity\n",
        "        self.capacity = capacity\n",
        "        # Initialize the memory as a list\n",
        "        self.memory = []\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Randomly sample a batch of experiences\n",
        "        experiences = random.sample(self.memory, k=batch_size)\n",
        "\n",
        "        # Extract each part of the experience tuple (state, action, reward, next_state, done)\n",
        "        states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences])).float().to(self.device)\n",
        "\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "        return states, next_states, actions, rewards, dones\n",
        "\n",
        "    def push(self, experience):\n",
        "        # Add the new experience to memory\n",
        "        self.memory.append(experience)\n",
        "\n",
        "        # If memory exceeds the capacity, remove the oldest experience\n",
        "        if len(self.memory) > self.capacity:\n",
        "            self.memory.pop(0)  # Remove the first item (FIFO - First In, First Out)\n",
        "    \n",
        "    \n",
        "# ==========================================\n",
        "# THE AGENT (The Logic)\n",
        "# ==========================================\n",
        "class Agent:\n",
        "    def __init__(self, config):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.network = MiniGridNet(config.input_shape, config.num_actions).to(self.device)\n",
        "        self.target_network = copy.deepcopy(self.network)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-4)\n",
        "        self.memory = ExperienceMemory(config.memory_size)\n",
        "        self.minibatch_size = config.minibatch_size\n",
        "        self.num_actions = config.num_actions\n",
        "\n",
        "    def _to_chw(self, x):\n",
        "        \"\"\"Convert (N, H, W, C) or (H, W, C) to (N, C, H, W) for Conv2d.\"\"\"\n",
        "        if x.dim() == 3 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(2, 0, 1).unsqueeze(0)\n",
        "        elif x.dim() == 4 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        return x\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.num_actions - 1)\n",
        "        with torch.no_grad():\n",
        "            if not torch.is_tensor(state):\n",
        "                state = torch.tensor(state, dtype=torch.float32)\n",
        "            state = state.to(self.device)\n",
        "            state = self._to_chw(state)\n",
        "            q_values = self.network(state)\n",
        "            return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def train_step(self, config):\n",
        "        states, next_states, actions, rewards, dones = self.memory.sample(self.minibatch_size)\n",
        "        states = self._to_chw(states)\n",
        "        next_states = self._to_chw(next_states)\n",
        "        actions = actions.unsqueeze(1)  # (B,) -> (B, 1) for gather(1, actions)\n",
        "\n",
        "        next_q_targets = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        q_targets = rewards + (config.discount_factor * next_q_targets * (1 - dones))\n",
        "        q_expected = self.network(states).gather(1, actions)\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #TODO update target network\n",
        "        #TODO undestand the different between the local and the target network\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_network.parameters(), self.network.parameters()):\n",
        "            target_param.data.copy_(local_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  MAIN TRAINING LOOP (Static Method)\n",
        "# ==========================================\n",
        "def run_training(env, agent, config, preprocess_observation):\n",
        "        \"\"\"\n",
        "        Run the main training loop. Hyperparameters (total_episodes, epsilon, frame_skipping, etc.) are read from config.\n",
        "        \"\"\"\n",
        "        total_steps = 0\n",
        "        epsilon = config.epsilon\n",
        "        for episode in range(config.total_episodes):\n",
        "            obs, info = env.reset()\n",
        "            done = False\n",
        "            while not done: #TODO check if max steps is used or not\n",
        "                #TODO check if preprocess is neede or is it already done in the step function\n",
        "                state = preprocess_observation(obs)\n",
        "                action = agent.select_action(state, epsilon)\n",
        "                next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "                done = terminated or truncated\n",
        "\n",
        "                #TODO handle score history for plotting\n",
        "\n",
        "                next_state = preprocess_observation(next_obs)\n",
        "                #TODO handel memory size\n",
        "                agent.memory.push((state, action, reward, next_state, done))\n",
        "\n",
        "                epsilon = max(config.epsilon_ending_value, config.epsilon_decay_value * epsilon)\n",
        "\n",
        "                # Update policy with frame skipping: train every `frame_skipping` env steps\n",
        "                if total_steps % config.frame_skipping == 0:\n",
        "                    agent.train_step(config)\n",
        "\n",
        "                total_steps += 1\n",
        "                #TODO check if need to update target network\n",
        "                obs = next_obs\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._inductor' has no attribute 'custom_graph_pass' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[143], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m Config(\n\u001b[1;32m      3\u001b[0m     env\u001b[38;5;241m=\u001b[39menv,\n\u001b[1;32m      4\u001b[0m     memory_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     frame_skipping\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m preprocess_observation \u001b[38;5;241m=\u001b[39m pre_process\n\u001b[0;32m---> 14\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m run_training(env, agent, config, preprocess_observation)\n",
            "Cell \u001b[0;32mIn[141], line 125\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m MiniGridNet(config\u001b[38;5;241m.\u001b[39minput_shape, config\u001b[38;5;241m.\u001b[39mnum_actions)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;241m=\u001b[39m ExperienceMemory(config\u001b[38;5;241m.\u001b[39mmemory_size)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mminibatch_size\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adam.py:101\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor betas[1] must be 1-element\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     89\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     90\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[1;32m    100\u001b[0m )\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:400\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    397\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_compile.py:46\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# We can safely turn off functools.wraps here because the inner\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# already wraps fn in the outer scope.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/convert_frame.py:53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/symbolic_convert.py:58\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     config,\n\u001b[1;32m     60\u001b[0m     exc,\n\u001b[1;32m     61\u001b[0m     graph_break_hints,\n\u001b[1;32m     62\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[1;32m     63\u001b[0m     trace_rules,\n\u001b[1;32m     64\u001b[0m     variables,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m     get_indexof,\n\u001b[1;32m     68\u001b[0m     JUMP_OPNAMES,\n\u001b[1;32m     69\u001b[0m     livevars_analysis,\n\u001b[1;32m     70\u001b[0m     propagate_line_nums,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     73\u001b[0m     cleaned_instructions,\n\u001b[1;32m     74\u001b[0m     create_call_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     unique_id,\n\u001b[1;32m     82\u001b[0m )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/trace_rules.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, cast, Optional, Union\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_operators\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_inductor/__init__.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, IO, Literal, Optional, TYPE_CHECKING, Union\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandalone_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompiledArtifact  \u001b[38;5;66;03m# noqa: TC001\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_inductor/config.py:261\u001b[0m\n\u001b[1;32m    254\u001b[0m b2b_gemm_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# register custom graph optimization pass hook. so far, pre/post passes are\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# only applied before/after pattern_matcher in post_grad_passes.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Implement CustomGraphPass to allow Inductor to graph compiled artifacts\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# to which your custom passes have been applied:\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m post_grad_custom_pre_pass: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inductor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_graph_pass\u001b[49m\u001b[38;5;241m.\u001b[39mCustomGraphPassType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    262\u001b[0m post_grad_custom_post_pass: torch\u001b[38;5;241m.\u001b[39m_inductor\u001b[38;5;241m.\u001b[39mcustom_graph_pass\u001b[38;5;241m.\u001b[39mCustomGraphPassType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Registers a custom joint graph pass.\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._inductor' has no attribute 'custom_graph_pass' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "# run the training loop (hyperparameters passed via config)\n",
        "config = Config(\n",
        "    env=env,\n",
        "    memory_size=1,\n",
        "    minibatch_size=1,\n",
        "    discount_factor=0.99,\n",
        "    total_episodes=1000,\n",
        "    epsilon=1.0,\n",
        "    epsilon_ending_value=0.01,\n",
        "    epsilon_decay_value=0.995,\n",
        "    frame_skipping=1,\n",
        ")\n",
        "preprocess_observation = pre_process\n",
        "agent = Agent(config)\n",
        "run_training(env, agent, config, preprocess_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

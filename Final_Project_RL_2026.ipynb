{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# üéÆ Deep RL Final Project ‚Äî MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## üåç The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8√ó8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key ‚Üí Open door ‚Üí Pick up ball ‚Üí Reach goal |\n",
        "\n",
        "## ‚úÖ What You CAN Modify\n",
        "- **Preprocessing** ‚Äî Implement your own observation preprocessing function.\n",
        "- **Reward shaping** ‚Äî Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** ‚Äî Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## ‚ùå What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## üì¶ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## üß™ Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## üßæ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> ‚ö†Ô∏è **Important**\n",
        ">\n",
        "> The two environments below are **fixed**‚Äîdo not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** ‚Äî set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** ‚Äî edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: State getter methods (use these in reward shaping)   ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> üí° **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320√ó320√ó3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) ‚Äî smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    #TODO check if check use several images\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# üîç Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8√ó8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    2\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key ‚Üí Door ‚Üí Ball ‚Üí Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key ‚Üí Open door ‚Üí Enter right room ‚Üí Pick up ball ‚Üí Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` ‚Äî True if agent has the key\n",
        "- `is_carrying_ball()` ‚Äî True if agent has the ball\n",
        "- `is_door_open()` ‚Äî True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(1), np.int64(1))\n",
            "Carrying key:    False\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"Select best available device: CUDA > MPS (Apple Silicon) > CPU.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda:0\")\n",
        "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")  # Apple Silicon GPU\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# Config (hyperparameters and env-derived settings)\n",
        "# ==========================================\n",
        "class Config:\n",
        "    \"\"\"Holds agent/environment config. Pass env to fill input_shape and num_actions from it.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env=None,\n",
        "        memory_size=10_000,\n",
        "        minibatch_size=64,\n",
        "        discount_factor=0.99,\n",
        "        total_episodes=1000,\n",
        "        epsilon=1.0,\n",
        "        epsilon_ending_value=0.01,\n",
        "        epsilon_decay_value=0.995,\n",
        "        frame_skipping=1,\n",
        "        **kwargs\n",
        "    ):\n",
        "        obs_space = env.observation_space\n",
        "        raw_shape = getattr(obs_space, \"shape\", (3, 84, 84))\n",
        "        # PyTorch Conv2d expects (C, H, W). If env gives (H, W, C), convert.\n",
        "        if len(raw_shape) == 3 and raw_shape[-1] in (1, 3):\n",
        "            self.input_shape = (raw_shape[-1], raw_shape[0], raw_shape[1])\n",
        "        else:\n",
        "            self.input_shape = raw_shape\n",
        "            self.num_actions = env.action_space.n\n",
        "        self.memory_size = memory_size\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.discount_factor = discount_factor\n",
        "        # Training loop hyperparameters\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_ending_value = epsilon_ending_value\n",
        "        self.epsilon_decay_value = epsilon_decay_value\n",
        "        self.frame_skipping = frame_skipping\n",
        "        self.num_actions = env.action_space.n\n",
        "\n",
        "# ==========================================\n",
        "# The Model\n",
        "# ==========================================\n",
        "class MiniGridNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, mode='value'):\n",
        "        super().__init__()\n",
        "        # input_shape must be (C, H, W) for Conv2d\n",
        "        c, h, w = input_shape[0], input_shape[1], input_shape[2]\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=16, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        # Compute conv output size so it works for any input (C, H, W)\n",
        "        def _conv_out(in_size, k, s):\n",
        "            return (in_size - k) // s + 1\n",
        "        h1, w1 = _conv_out(h, 8, 4), _conv_out(w, 8, 4)\n",
        "        h2, w2 = _conv_out(h1, 4, 2), _conv_out(w1, 4, 2)\n",
        "        flat_size = 32 * h2 * w2\n",
        "\n",
        "        self.q_head = nn.Sequential(\n",
        "            nn.Linear(flat_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.q_head(features)\n",
        "\n",
        "# ==========================================\n",
        "# THE MEMORY\n",
        "# ==========================================\n",
        "class ExperienceMemory:\n",
        "    def __init__(self, capacity, is_on_policy=False):\n",
        "        # Use GPU if available (CUDA or MPS for Apple Silicon), otherwise CPU\n",
        "        self.device = get_device()\n",
        "        # Set the maximum memory capacity\n",
        "        self.capacity = capacity\n",
        "        # Initialize the memory as a list\n",
        "        self.memory = []\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Randomly sample a batch of experiences\n",
        "        experiences = random.sample(self.memory, k=batch_size)\n",
        "\n",
        "        # Extract each part of the experience tuple (state, action, reward, next_state, done)\n",
        "        states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences])).float().to(self.device)\n",
        "\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "        return states, next_states, actions, rewards, dones\n",
        "\n",
        "    def push(self, experience):\n",
        "        # Add the new experience to memory\n",
        "        self.memory.append(experience)\n",
        "\n",
        "        # If memory exceeds the capacity, remove the oldest experience\n",
        "        if len(self.memory) > self.capacity:\n",
        "            self.memory.pop(0)  # Remove the first item (FIFO - First In, First Out)\n",
        "    \n",
        "    \n",
        "# ==========================================\n",
        "# THE AGENT (The Logic)\n",
        "# ==========================================\n",
        "class Agent:\n",
        "    def __init__(self, config):\n",
        "        self.device = get_device()  # CUDA GPU > MPS (Apple Silicon) > CPU\n",
        "        self.network = MiniGridNet(config.input_shape, config.num_actions).to(self.device)\n",
        "        self.target_network = copy.deepcopy(self.network)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-4)\n",
        "        self.memory = ExperienceMemory(config.memory_size)\n",
        "        self.minibatch_size = config.minibatch_size\n",
        "        self.num_actions = config.num_actions\n",
        "\n",
        "    def _to_chw(self, x):\n",
        "        \"\"\"Convert (N, H, W, C) or (H, W, C) to (N, C, H, W) for Conv2d.\"\"\"\n",
        "        if x.dim() == 3 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(2, 0, 1).unsqueeze(0)\n",
        "        elif x.dim() == 4 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        return x\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.num_actions - 1)\n",
        "        with torch.no_grad():\n",
        "            if not torch.is_tensor(state):\n",
        "                state = torch.tensor(state, dtype=torch.float32)\n",
        "            state = state.to(self.device)\n",
        "            state = self._to_chw(state)\n",
        "            q_values = self.network(state)\n",
        "            return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def train_step(self, config):\n",
        "        states, next_states, actions, rewards, dones = self.memory.sample(self.minibatch_size)\n",
        "        states = self._to_chw(states)\n",
        "        next_states = self._to_chw(next_states)\n",
        "        actions = actions.view(-1, 1)\n",
        "\n",
        "        next_q_targets = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        q_targets = rewards + (config.discount_factor * next_q_targets * (1 - dones))\n",
        "        q_expected = self.network(states).gather(1, actions.to(self.device))\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #TODO update target network\n",
        "        #TODO undestand the different between the local and the target network\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_network.parameters(), self.network.parameters()):\n",
        "            target_param.data.copy_(local_param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: mps\n",
            "GPU: Apple Silicon (MPS)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell anytime to see if you're on CPU or GPU (run after the cell that defines get_device)\n",
        "device = get_device()\n",
        "print(\"Running on:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "elif device.type == \"mps\":\n",
        "    print(\"GPU: Apple Silicon (MPS)\")\n",
        "else:\n",
        "    print(\"GPU: None (CPU only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_training_setup(env, config, agent):\n",
        "    \"\"\"Print important config, agent, and network parameters before training.\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"CONFIG\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  env:                  {env.spec.id if env.spec else type(env).__name__}\")\n",
        "    print(f\"  observation shape:   {config.input_shape} (C, H, W)\")\n",
        "    print(f\"  num_actions:         {config.num_actions}\")\n",
        "    print(f\"  memory_size:         {config.memory_size}\")\n",
        "    print(f\"  minibatch_size:      {config.minibatch_size}\")\n",
        "    print(f\"  discount_factor:     {config.discount_factor}\")\n",
        "    print(f\"  total_episodes:      {config.total_episodes}\")\n",
        "    print(f\"  epsilon:             {config.epsilon} -> {config.epsilon_ending_value} (decay {config.epsilon_decay_value})\")\n",
        "    print(f\"  frame_skipping:      {config.frame_skipping}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"AGENT / NETWORK\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  device:              {agent.device}\")\n",
        "    n_params = sum(p.numel() for p in agent.network.parameters())\n",
        "    print(f\"  network parameters:  {n_params:,}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "\n",
        "def plot_training_progress(scores, window_size=50):\n",
        "    \"\"\"\n",
        "    Plot the training progress of a DQN agent\n",
        "\n",
        "    Args:\n",
        "        scores (list): List of scores from each episode\n",
        "        window_size (int): Size of the moving average window\n",
        "    \"\"\"\n",
        "    # Convert to numpy array for easier manipulation\n",
        "    scores = np.array(scores)\n",
        "\n",
        "    # Calculate moving average\n",
        "    moving_averages = []\n",
        "    for i in range(len(scores)):\n",
        "        if i < window_size:\n",
        "            moving_averages.append(np.mean(scores[:i+1]))\n",
        "        else:\n",
        "            moving_averages.append(np.mean(scores[i-window_size+1:i+1]))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(scores, label='Score', alpha=0.3, color='blue')\n",
        "    plt.plot(moving_averages, label=f'{window_size}-episode Moving Average',\n",
        "             color='red', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('DQN Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add horizontal line at score 200 (solving threshold)\n",
        "    plt.axhline(y=200, color='green', linestyle='--', alpha=0.5,\n",
        "                label='Solving Threshold')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  MAIN TRAINING LOOP (Static Method)\n",
        "# ==========================================\n",
        "def run_training(env, agent, config, preprocess_observation, print_every=10):\n",
        "        \"\"\"\n",
        "        Run the main training loop. Hyperparameters (total_episodes, epsilon, frame_skipping, etc.) are read from config.\n",
        "        \"\"\"\n",
        "        total_steps = 0\n",
        "        epsilon = config.epsilon\n",
        "        print(f\"Starting training: {config.total_episodes} episodes, epsilon={epsilon:.3f} -> {config.epsilon_ending_value:.3f}\")\n",
        "        print(\"-\" * 60)\n",
        "        for episode in range(config.total_episodes):\n",
        "            obs, info = env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "            episode_steps = 0\n",
        "            while not done: #TODO check if max steps is used or not\n",
        "                #TODO check if preprocess is neede or is it already done in the step function\n",
        "                state = preprocess_observation(obs)\n",
        "                action = agent.select_action(state, epsilon)\n",
        "                next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "                done = terminated or truncated\n",
        "                episode_reward += reward\n",
        "                episode_steps += 1\n",
        "\n",
        "                #TODO handle score history for plotting\n",
        "\n",
        "                next_state = preprocess_observation(next_obs)\n",
        "                #TODO handel memory size\n",
        "                agent.memory.push((state, action, reward, next_state, done))\n",
        "\n",
        "                epsilon = max(config.epsilon_ending_value, config.epsilon_decay_value * epsilon)\n",
        "\n",
        "                # Update policy with frame skipping: train every `frame_skipping` env steps\n",
        "                if total_steps % config.frame_skipping == 0:\n",
        "                    agent.train_step(config)\n",
        "\n",
        "                total_steps += 1\n",
        "                #TODO check if need to update target network\n",
        "                obs = next_obs\n",
        "\n",
        "            if (episode + 1) % print_every == 0 or episode == 0:\n",
        "                print(f\"Episode {episode + 1:5d}/{config.total_episodes} | reward: {episode_reward:7.2f} | steps: {episode_steps:4d} | epsilon: {epsilon:.3f} | total_steps: {total_steps}\")\n",
        "        print(\"-\" * 60)\n",
        "        print(\"Training finished.\")\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CONFIG\n",
            "==================================================\n",
            "  env:                  KeyDoorBallEnv\n",
            "  observation shape:   (3, 84, 84) (C, H, W)\n",
            "  num_actions:         5\n",
            "  memory_size:         1\n",
            "  minibatch_size:      1\n",
            "  discount_factor:     0.99\n",
            "  total_episodes:      1000\n",
            "  epsilon:             1.0 -> 0.01 (decay 0.995)\n",
            "  frame_skipping:      1\n",
            "==================================================\n",
            "AGENT / NETWORK\n",
            "==================================================\n",
            "  device:              mps\n",
            "  network parameters:  1,341,493\n",
            "==================================================\n",
            "Starting training: 1000 episodes, epsilon=1.000 -> 0.010\n",
            "------------------------------------------------------------\n",
            "Episode     1/1000 | reward:    0.00 | steps:  100 | epsilon: 0.606 | total_steps: 100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[75], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  network parameters:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_params\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_observation\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[73], line 20\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(env, agent, config, preprocess_observation, print_every)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done: \u001b[38;5;66;03m#TODO check if max steps is used or not\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#TODO check if preprocess is neede or is it already done in the step function\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     state \u001b[38;5;241m=\u001b[39m preprocess_observation(obs)\n\u001b[0;32m---> 20\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     next_obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     22\u001b[0m     done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
            "Cell \u001b[0;32mIn[70], line 152\u001b[0m, in \u001b[0;36mAgent.select_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m    150\u001b[0m state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    151\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_chw(state)\n\u001b[0;32m--> 152\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_values\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[70], line 85\u001b[0m, in \u001b[0;36mMiniGridNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     84\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_head\u001b[49m(features)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1955\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _parameters[name]\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m-> 1955\u001b[0m     _buffers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_buffers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _buffers:\n\u001b[1;32m   1957\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _buffers[name]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# run the training loop (hyperparameters passed via config)\n",
        "config = Config(\n",
        "    env=env,\n",
        "    memory_size=1,\n",
        "    minibatch_size=1,\n",
        "    discount_factor=0.99,\n",
        "    total_episodes=1000,\n",
        "    epsilon=1.0,\n",
        "    epsilon_ending_value=0.01,\n",
        "    epsilon_decay_value=0.995,\n",
        "    frame_skipping=1\n",
        ")\n",
        "preprocess_observation = pre_process\n",
        "agent = Agent(config)\n",
        "\n",
        "print_training_setup(env, config, agent)\n",
        "\n",
        "run_training(env, agent, config, preprocess_observation)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

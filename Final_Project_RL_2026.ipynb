{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# ğŸ® Deep RL Final Project â€” MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## ğŸŒ The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8Ã—8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key â†’ Open door â†’ Pick up ball â†’ Reach goal |\n",
        "\n",
        "## âœ… What You CAN Modify\n",
        "- **Preprocessing** â€” Implement your own observation preprocessing function.\n",
        "- **Reward shaping** â€” Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** â€” Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## âŒ What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## ğŸ“¦ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## ğŸ§ª Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## ğŸ§¾ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> âš ï¸ **Important**\n",
        ">\n",
        "> The two environments below are **fixed**â€”do not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** â€” set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** â€” edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘  âœ… STUDENT TODO: Update observation_space to match preprocessing   â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘                     END OF EDITABLE SECTION                         â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: Core environment methods below                       â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  âœ… STUDENT TODO: Modify reward shaping below                           â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        ğŸ’¡ You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘                     END OF EDITABLE SECTION                             â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘  âœ… STUDENT TODO: Update observation_space to match preprocessing   â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘                     END OF EDITABLE SECTION                         â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: Core environment methods below                       â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  âœ… STUDENT TODO: Modify reward shaping below                           â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        ğŸ’¡ You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘                     END OF EDITABLE SECTION                             â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: State getter methods (use these in reward shaping)   â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> ğŸ’¡ **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320Ã—320Ã—3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) â€” smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Frame stacking: stack the last N frames so the agent sees motion/direction\n",
        "from gymnasium import spaces\n",
        "\n",
        "NUM_STACK = 4  # number of frames to stack (3 or 4)\n",
        "\n",
        "class FrameStackWrapper:\n",
        "    \"\"\"\n",
        "    Wraps an env and returns the last num_frames observations stacked along the channel dimension.\n",
        "    Single frame: (H, W, C) -> Stacked: (H, W, C * num_frames).\n",
        "    On reset, the buffer is filled with the first frame repeated (no motion at start).\n",
        "    \"\"\"\n",
        "    def __init__(self, env, num_frames=4):\n",
        "        self.env = env\n",
        "        self.num_frames = num_frames\n",
        "        self._buffer = []\n",
        "        # observation_space: same shape but last dim = C * num_frames\n",
        "        single = env.observation_space\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=single.low, high=single.high,\n",
        "            shape=(*single.shape[:-1], single.shape[-1] * num_frames),\n",
        "            dtype=single.dtype,\n",
        "        )\n",
        "        self.action_space = env.action_space\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        obs, info = self.env.reset(seed=seed, options=options)\n",
        "        self._buffer = [np.array(obs, copy=True) for _ in range(self.num_frames)]\n",
        "        return self._stack(), info\n",
        "\n",
        "    def _stack(self):\n",
        "        return np.concatenate(self._buffer, axis=-1)\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
        "        self._buffer.pop(0)\n",
        "        self._buffer.append(np.array(obs, copy=True))\n",
        "        return self._stack(), reward, terminated, truncated, info\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        return getattr(self.env, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# ğŸ” Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8Ã—8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8Ã—8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Box low.shape doesn't match provided shape, low.shape=(84, 84, 3), shape=(84, 84, 12)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize environment with preprocessing + frame stacking (last 4 frames)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mFrameStackWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSimpleGridEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_process\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_STACK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== SimpleGridEnv (with frame stacking) ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[74], line 18\u001b[0m, in \u001b[0;36mFrameStackWrapper.__init__\u001b[0;34m(self, env, num_frames)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# observation_space: same shape but last dim = C * num_frames\u001b[39;00m\n\u001b[1;32m     17\u001b[0m single \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m \u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/spaces/box.py:152\u001b[0m, in \u001b[0;36mBox.__init__\u001b[0;34m(self, low, high, shape, dtype, seed)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# recheck shape for case where shape and (low or high) are provided\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m shape:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBox low.shape doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match provided shape, low.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m shape:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBox high.shape doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match provided shape, high.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Box low.shape doesn't match provided shape, low.shape=(84, 84, 3), shape=(84, 84, 12)"
          ]
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key â†’ Door â†’ Ball â†’ Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8Ã—8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key â†’ Open door â†’ Enter right room â†’ Pick up ball â†’ Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` â€” True if agent has the key\n",
        "- `is_carrying_ball()` â€” True if agent has the ball\n",
        "- `is_door_open()` â€” True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(2), np.int64(3))\n",
            "Carrying key:    False\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

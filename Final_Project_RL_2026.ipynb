{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# üéÆ Deep RL Final Project ‚Äî MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## üåç The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8√ó8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key ‚Üí Open door ‚Üí Pick up ball ‚Üí Reach goal |\n",
        "\n",
        "## ‚úÖ What You CAN Modify\n",
        "- **Preprocessing** ‚Äî Implement your own observation preprocessing function.\n",
        "- **Reward shaping** ‚Äî Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** ‚Äî Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## ‚ùå What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## üì¶ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## üß™ Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## üßæ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> ‚ö†Ô∏è **Important**\n",
        ">\n",
        "> The two environments below are **fixed**‚Äîdo not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** ‚Äî set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** ‚Äî edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: State getter methods (use these in reward shaping)   ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> üí° **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320√ó320√ó3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) ‚Äî smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    #TODO check if check use several images\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# üîç Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8√ó8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (4, 6)\n",
            "Goal position:      (8, 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key ‚Üí Door ‚Üí Ball ‚Üí Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key ‚Üí Open door ‚Üí Enter right room ‚Üí Pick up ball ‚Üí Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` ‚Äî True if agent has the key\n",
        "- `is_carrying_ball()` ‚Äî True if agent has the ball\n",
        "- `is_door_open()` ‚Äî True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(1), np.int64(3))\n",
            "Carrying key:    False\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"Select best available device: CUDA > MPS (Apple Silicon) > CPU.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda:0\")\n",
        "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")  # Apple Silicon GPU\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# Config (hyperparameters and env-derived settings)\n",
        "# ==========================================\n",
        "class Config:\n",
        "    \"\"\"Holds agent/environment config. Pass env to fill input_shape and num_actions from it.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env=None,\n",
        "        memory_size=10_000,\n",
        "        minibatch_size=64,\n",
        "        discount_factor=0.99,\n",
        "        total_episodes=1000,\n",
        "        epsilon=1.0,\n",
        "        epsilon_ending_value=0.01,\n",
        "        epsilon_decay_value=0.995,\n",
        "        frame_skipping=1,\n",
        "        **kwargs\n",
        "    ):\n",
        "        obs_space = env.observation_space\n",
        "        raw_shape = getattr(obs_space, \"shape\", (3, 84, 84))\n",
        "        # PyTorch Conv2d expects (C, H, W). If env gives (H, W, C), convert.\n",
        "        if len(raw_shape) == 3 and raw_shape[-1] in (1, 3):\n",
        "            self.input_shape = (raw_shape[-1], raw_shape[0], raw_shape[1])\n",
        "        else:\n",
        "            self.input_shape = raw_shape\n",
        "            self.num_actions = env.action_space.n\n",
        "        self.memory_size = memory_size\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.discount_factor = discount_factor\n",
        "        # Training loop hyperparameters\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_ending_value = epsilon_ending_value\n",
        "        self.epsilon_decay_value = epsilon_decay_value\n",
        "        self.frame_skipping = frame_skipping\n",
        "        self.num_actions = env.action_space.n\n",
        "\n",
        "# ==========================================\n",
        "# The Model\n",
        "# ==========================================\n",
        "class MiniGridNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, mode='value'):\n",
        "        super().__init__()\n",
        "        # input_shape must be (C, H, W) for Conv2d\n",
        "        c, h, w = input_shape[0], input_shape[1], input_shape[2]\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=16, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        # Compute conv output size so it works for any input (C, H, W)\n",
        "        def _conv_out(in_size, k, s):\n",
        "            return (in_size - k) // s + 1\n",
        "        h1, w1 = _conv_out(h, 8, 4), _conv_out(w, 8, 4)\n",
        "        h2, w2 = _conv_out(h1, 4, 2), _conv_out(w1, 4, 2)\n",
        "        flat_size = 32 * h2 * w2\n",
        "\n",
        "        self.q_head = nn.Sequential(\n",
        "            nn.Linear(flat_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.q_head(features)\n",
        "\n",
        "# ==========================================\n",
        "# THE MEMORY\n",
        "# ==========================================\n",
        "class ExperienceMemory:\n",
        "    def __init__(self, capacity, is_on_policy=False):\n",
        "        # Use GPU if available (CUDA or MPS for Apple Silicon), otherwise CPU\n",
        "        self.device = get_device()\n",
        "        # Set the maximum memory capacity\n",
        "        self.capacity = capacity\n",
        "        # Initialize the memory as a list\n",
        "        self.memory = []\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Randomly sample a batch of experiences\n",
        "        experiences = random.sample(self.memory, k=batch_size)\n",
        "\n",
        "        # Extract each part of the experience tuple (state, action, reward, next_state, done)\n",
        "        states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences])).float().to(self.device)\n",
        "\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "        return states, next_states, actions, rewards, dones\n",
        "\n",
        "    def push(self, experience):\n",
        "        # Add the new experience to memory\n",
        "        self.memory.append(experience)\n",
        "\n",
        "        # If memory exceeds the capacity, remove the oldest experience\n",
        "        if len(self.memory) > self.capacity:\n",
        "            self.memory.pop(0)  # Remove the first item (FIFO - First In, First Out)\n",
        "    \n",
        "    \n",
        "# ==========================================\n",
        "# THE AGENT (The Logic)\n",
        "# ==========================================\n",
        "class Agent:\n",
        "    def __init__(self, config):\n",
        "        self.device = get_device()  # CUDA GPU > MPS (Apple Silicon) > CPU\n",
        "        self.network = MiniGridNet(config.input_shape, config.num_actions).to(self.device)\n",
        "        self.target_network = copy.deepcopy(self.network)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-4)\n",
        "        self.memory = ExperienceMemory(config.memory_size)\n",
        "        self.minibatch_size = config.minibatch_size\n",
        "        self.num_actions = config.num_actions\n",
        "\n",
        "    def _to_chw(self, x):\n",
        "        \"\"\"Convert (N, H, W, C) or (H, W, C) to (N, C, H, W) for Conv2d.\"\"\"\n",
        "        if x.dim() == 3 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(2, 0, 1).unsqueeze(0)\n",
        "        elif x.dim() == 4 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        return x\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.num_actions - 1)\n",
        "        with torch.no_grad():\n",
        "            if not torch.is_tensor(state):\n",
        "                state = torch.tensor(state, dtype=torch.float32)\n",
        "            state = state.to(self.device)\n",
        "            state = self._to_chw(state)\n",
        "            q_values = self.network(state)\n",
        "            return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def train_step(self, config):\n",
        "        states, next_states, actions, rewards, dones = self.memory.sample(self.minibatch_size)\n",
        "        states = self._to_chw(states)\n",
        "        next_states = self._to_chw(next_states)\n",
        "        actions = actions.view(-1, 1)\n",
        "\n",
        "        next_q_targets = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        q_targets = rewards + (config.discount_factor * next_q_targets * (1 - dones))\n",
        "        q_expected = self.network(states).gather(1, actions.to(self.device))\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #TODO update target network\n",
        "        #TODO undestand the different between the local and the target network\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_network.parameters(), self.network.parameters()):\n",
        "            target_param.data.copy_(local_param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: mps\n",
            "GPU: Apple Silicon (MPS)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell anytime to see if you're on CPU or GPU (run after the cell that defines get_device)\n",
        "device = get_device()\n",
        "print(\"Running on:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "elif device.type == \"mps\":\n",
        "    print(\"GPU: Apple Silicon (MPS)\")\n",
        "else:\n",
        "    print(\"GPU: None (CPU only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_training_setup(env, config, agent):\n",
        "    \"\"\"Print important config, agent, and network parameters before training.\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"CONFIG\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  env:                  {env.spec.id if env.spec else type(env).__name__}\")\n",
        "    print(f\"  observation shape:   {config.input_shape} (C, H, W)\")\n",
        "    print(f\"  num_actions:         {config.num_actions}\")\n",
        "    print(f\"  memory_size:         {config.memory_size}\")\n",
        "    print(f\"  minibatch_size:      {config.minibatch_size}\")\n",
        "    print(f\"  discount_factor:     {config.discount_factor}\")\n",
        "    print(f\"  total_episodes:      {config.total_episodes}\")\n",
        "    print(f\"  epsilon:             {config.epsilon} -> {config.epsilon_ending_value} (decay {config.epsilon_decay_value})\")\n",
        "    print(f\"  frame_skipping:      {config.frame_skipping}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"AGENT / NETWORK\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  device:              {agent.device}\")\n",
        "    n_params = sum(p.numel() for p in agent.network.parameters())\n",
        "    print(f\"  network parameters:  {n_params:,}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Window size for rolling average (last N episodes)\n",
        "LAST_EPISODES = 300\n",
        "scores_on_last_windowSize_episodes = deque(maxlen=LAST_EPISODES)\n",
        "\n",
        "\n",
        "def plot_training_progress(scores, window_size=50, solving_threshold=None):\n",
        "    \"\"\"\n",
        "    Plot the training progress of a DQN agent.\n",
        "\n",
        "    Args:\n",
        "        scores (list): List of scores from each episode\n",
        "        window_size (int): Size of the moving average window\n",
        "        solving_threshold (float, optional): If set, draw a horizontal line at this score.\n",
        "                                             For MiniGrid use e.g. 1.0 or None to omit.\n",
        "    \"\"\"\n",
        "    scores = np.array(scores)\n",
        "\n",
        "    moving_averages = []\n",
        "    for i in range(len(scores)):\n",
        "        if i < window_size:\n",
        "            moving_averages.append(np.mean(scores[:i+1]))\n",
        "        else:\n",
        "            moving_averages.append(np.mean(scores[i-window_size+1:i+1]))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(scores, label='Score', alpha=0.3, color='blue')\n",
        "    plt.plot(moving_averages, label=f'{window_size}-episode Moving Average',\n",
        "             color='red', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('DQN Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    if solving_threshold is not None:\n",
        "        plt.axhline(y=solving_threshold, color='green', linestyle='--', alpha=0.5,\n",
        "                    label='Solving Threshold')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  MAIN TRAINING LOOP (Static Method)\n",
        "# ==========================================\n",
        "def run_training(env, agent, config, print_every=100,\n",
        "                 solving_threshold=None, checkpoint_path='checkpoint.pth'):\n",
        "    \"\"\"\n",
        "    Run the main training loop. Returns scores_history for plotting.\n",
        "    Hyperparameters (total_episodes, epsilon, frame_skipping, etc.) are read from config.\n",
        "    \"\"\"\n",
        "    total_steps = 0\n",
        "    epsilon = config.epsilon\n",
        "    scores_history = []\n",
        "    scores_window = deque(maxlen=LAST_EPISODES)\n",
        "    print(f\"Starting training: {config.total_episodes} episodes, epsilon={epsilon:.3f} -> {config.epsilon_ending_value:.3f}\")\n",
        "    print(\"-\" * 60)\n",
        "    for episode in range(config.total_episodes):\n",
        "        obs, info = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        episode_steps = 0\n",
        "        while not done:  # TODO check if max steps is used or not\n",
        "            action = agent.select_action(obs, epsilon)\n",
        "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "            episode_steps += 1\n",
        "\n",
        "            # TODO handle score history for plotting (per-step if needed)\n",
        "\n",
        "            # TODO handle memory size\n",
        "            agent.memory.push((obs, action, reward, next_obs, done))\n",
        "\n",
        "            if total_steps % config.frame_skipping == 0:\n",
        "                agent.train_step(config)\n",
        "\n",
        "            total_steps += 1\n",
        "            # TODO check if need to update target network\n",
        "            obs = next_obs\n",
        "        \n",
        "        epsilon = max(config.epsilon_ending_value, config.epsilon_decay_value * epsilon)\n",
        "\n",
        "        scores_history.append(episode_reward)\n",
        "        scores_window.append(episode_reward)\n",
        "\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpsilon: {:.4f}'.format(\n",
        "            episode + 1, np.mean(scores_window), epsilon), end=\"\")\n",
        "\n",
        "        if (episode + 1) % print_every == 0:\n",
        "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpsilon: {:.4f}'.format(\n",
        "                episode + 1, np.mean(scores_window), epsilon))\n",
        "\n",
        "        if solving_threshold is not None and len(scores_window) == LAST_EPISODES:\n",
        "            if np.mean(scores_window) >= solving_threshold:\n",
        "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(\n",
        "                    episode + 1 - LAST_EPISODES, np.mean(scores_window)))\n",
        "                torch.save(agent.network.state_dict(), checkpoint_path)\n",
        "                break\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    print(\"Training finished.\")\n",
        "    return scores_history\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CONFIG\n",
            "==================================================\n",
            "  env:                  KeyDoorBallEnv\n",
            "  observation shape:   (3, 84, 84) (C, H, W)\n",
            "  num_actions:         3\n",
            "  memory_size:         1\n",
            "  minibatch_size:      1\n",
            "  discount_factor:     0.99\n",
            "  total_episodes:      1000\n",
            "  epsilon:             1.0 -> 0.01 (decay 0.995)\n",
            "  frame_skipping:      1\n",
            "==================================================\n",
            "AGENT / NETWORK\n",
            "==================================================\n",
            "  device:              mps\n",
            "  network parameters:  1,340,467\n",
            "==================================================\n",
            "Starting training: 1000 episodes, epsilon=1.000 -> 0.010\n",
            "------------------------------------------------------------\n",
            "Episode 56\tAverage Score: 0.00\tEpsilon: 0.0100"
          ]
        }
      ],
      "source": [
        "current_env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "# run the training loop (hyperparameters passed via config)\n",
        "config = Config(\n",
        "    env=current_env,\n",
        "    memory_size=1,\n",
        "    minibatch_size=1,\n",
        "    discount_factor=0.99,\n",
        "    total_episodes=1000,\n",
        "    epsilon=1.0,\n",
        "    epsilon_ending_value=0.01,\n",
        "    epsilon_decay_value=0.995,\n",
        "    frame_skipping=1\n",
        ")\n",
        "agent = Agent(config)\n",
        "\n",
        "print_training_setup(env, config, agent)\n",
        "\n",
        "# Run training and collect scores for plotting (solving_threshold=None for MiniGrid; set e.g. 1.0 to stop early)\n",
        "scores_history = run_training(env, agent, config, print_every=100,\n",
        "                               solving_threshold=None, checkpoint_path='checkpoint.pth')\n",
        "\n",
        "# Plot training progress (solving_threshold=None omits the green line; set e.g. 200 for CartPole-style)\n",
        "plot_training_progress(scores_history, window_size=50, solving_threshold=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

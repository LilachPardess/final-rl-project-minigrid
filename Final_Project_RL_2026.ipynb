{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# üéÆ Deep RL Final Project ‚Äî MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## üåç The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8√ó8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key ‚Üí Open door ‚Üí Pick up ball ‚Üí Reach goal |\n",
        "\n",
        "## ‚úÖ What You CAN Modify\n",
        "- **Preprocessing** ‚Äî Implement your own observation preprocessing function.\n",
        "- **Reward shaping** ‚Äî Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** ‚Äî Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## ‚ùå What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## üì¶ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## üß™ Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## üßæ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> ‚ö†Ô∏è **Important**\n",
        ">\n",
        "> The two environments below are **fixed**‚Äîdo not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** ‚Äî set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** ‚Äî edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: State getter methods (use these in reward shaping)   ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> üí° **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320√ó320√ó3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n",
            "objc[71049]: Class SDLApplication is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd2c8) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928890). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLAppDelegate is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd318) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x1139288e0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLTranslatorResponder is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd390) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928958). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLMessageBoxPresenter is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd3b8) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928980). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_cocoametalview is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd408) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x1139289d0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLOpenGLContext is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd458) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928a20). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_ShapeData is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd4d0) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928a98). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_CocoaClosure is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd520) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928ae8). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_VideoData is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd570) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928b38). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_WindowData is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd5c0) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928b88). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLWindow is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd5e8) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928bb0). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class Cocoa_WindowListener is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd610) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928bd8). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDLView is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd688) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928c50). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class METAL_RenderData is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd700) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928cc8). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class METAL_TextureData is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd750) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928d18). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_RumbleMotor is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd778) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928d40). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
            "objc[71049]: Class SDL_RumbleContext is implemented in both /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x10abfd7c8) and /Users/lilachpardess/Library/Python/3.9/lib/python/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x113928d90). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) ‚Äî smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    #TODO check if check use several images\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# üîç Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8√ó8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (4, 1)\n",
            "Goal position:      (8, 8)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key ‚Üí Door ‚Üí Ball ‚Üí Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key ‚Üí Open door ‚Üí Enter right room ‚Üí Pick up ball ‚Üí Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` ‚Äî True if agent has the key\n",
        "- `is_carrying_ball()` ‚Äî True if agent has the ball\n",
        "- `is_door_open()` ‚Äî True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(1), np.int64(2))\n",
            "Carrying key:    False\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================\n",
        "# Config (hyperparameters and env-derived settings)\n",
        "# ==========================================\n",
        "class Config:\n",
        "    \"\"\"Holds agent/environment config. Pass env to fill input_shape and num_actions from it.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env=None,\n",
        "        memory_size=10_000,\n",
        "        minibatch_size=64,\n",
        "        discount_factor=0.99,\n",
        "        total_episodes=1000,\n",
        "        epsilon=1.0,\n",
        "        epsilon_ending_value=0.01,\n",
        "        epsilon_decay_value=0.995,\n",
        "        frame_skipping=1,\n",
        "        **kwargs\n",
        "    ):\n",
        "        obs_space = env.observation_space\n",
        "        raw_shape = getattr(obs_space, \"shape\", (3, 84, 84))\n",
        "        # PyTorch Conv2d expects (C, H, W). If env gives (H, W, C), convert.\n",
        "        if len(raw_shape) == 3 and raw_shape[-1] in (1, 3):\n",
        "            self.input_shape = (raw_shape[-1], raw_shape[0], raw_shape[1])\n",
        "        else:\n",
        "            self.input_shape = raw_shape\n",
        "            self.num_actions = env.action_space.n\n",
        "        self.memory_size = memory_size\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.discount_factor = discount_factor\n",
        "        # Training loop hyperparameters\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_ending_value = epsilon_ending_value\n",
        "        self.epsilon_decay_value = epsilon_decay_value\n",
        "        self.frame_skipping = frame_skipping\n",
        "        self.num_actions = env.action_space.n\n",
        "\n",
        "# ==========================================\n",
        "# The Model\n",
        "# ==========================================\n",
        "class MiniGridNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions, mode='value'):\n",
        "        super().__init__()\n",
        "        # input_shape must be (C, H, W) for Conv2d\n",
        "        c, h, w = input_shape[0], input_shape[1], input_shape[2]\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=c, out_channels=16, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        # Compute conv output size so it works for any input (C, H, W)\n",
        "        def _conv_out(in_size, k, s):\n",
        "            return (in_size - k) // s + 1\n",
        "        h1, w1 = _conv_out(h, 8, 4), _conv_out(w, 8, 4)\n",
        "        h2, w2 = _conv_out(h1, 4, 2), _conv_out(w1, 4, 2)\n",
        "        flat_size = 32 * h2 * w2\n",
        "\n",
        "        self.q_head = nn.Sequential(\n",
        "            nn.Linear(flat_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.q_head(features)\n",
        "\n",
        "# ==========================================\n",
        "# THE MEMORY\n",
        "# ==========================================\n",
        "class ExperienceMemory:\n",
        "    def __init__(self, capacity, is_on_policy=False):\n",
        "        # Use GPU if available, otherwise fall back to CPU\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # Set the maximum memory capacity\n",
        "        self.capacity = capacity\n",
        "        # Initialize the memory as a list\n",
        "        self.memory = []\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Randomly sample a batch of experiences\n",
        "        experiences = random.sample(self.memory, k=batch_size)\n",
        "\n",
        "        # Extract each part of the experience tuple (state, action, reward, next_state, done)\n",
        "        states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.vstack([e[3] for e in experiences])).float().to(self.device)\n",
        "\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "        return states, next_states, actions, rewards, dones\n",
        "\n",
        "    def push(self, experience):\n",
        "        # Add the new experience to memory\n",
        "        self.memory.append(experience)\n",
        "\n",
        "        # If memory exceeds the capacity, remove the oldest experience\n",
        "        if len(self.memory) > self.capacity:\n",
        "            self.memory.pop(0)  # Remove the first item (FIFO - First In, First Out)\n",
        "    \n",
        "    \n",
        "# ==========================================\n",
        "# THE AGENT (The Logic)\n",
        "# ==========================================\n",
        "class Agent:\n",
        "    def __init__(self, config):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.network = MiniGridNet(config.input_shape, config.num_actions).to(self.device)\n",
        "        self.target_network = copy.deepcopy(self.network)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-4)\n",
        "        self.memory = ExperienceMemory(config.memory_size)\n",
        "        self.minibatch_size = config.minibatch_size\n",
        "        self.num_actions = config.num_actions\n",
        "\n",
        "    def _to_chw(self, x):\n",
        "        \"\"\"Convert (N, H, W, C) or (H, W, C) to (N, C, H, W) for Conv2d.\"\"\"\n",
        "        if x.dim() == 3 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(2, 0, 1).unsqueeze(0)\n",
        "        elif x.dim() == 4 and x.shape[-1] in (1, 3):\n",
        "            x = x.permute(0, 3, 1, 2).contiguous()\n",
        "        return x\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.num_actions - 1)\n",
        "        with torch.no_grad():\n",
        "            if not torch.is_tensor(state):\n",
        "                state = torch.tensor(state, dtype=torch.float32)\n",
        "            state = state.to(self.device)\n",
        "            state = self._to_chw(state)\n",
        "            q_values = self.network(state)\n",
        "            return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def train_step(self, config):\n",
        "        states, next_states, actions, rewards, dones = self.memory.sample(self.minibatch_size)\n",
        "        states = self._to_chw(states)\n",
        "        next_states = self._to_chw(next_states)\n",
        "        actions = actions.view(-1, 1)\n",
        "\n",
        "        next_q_targets = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        q_targets = rewards + (config.discount_factor * next_q_targets * (1 - dones))\n",
        "        q_expected = self.network(states).gather(1, actions.to(self.device))\n",
        "        loss = F.mse_loss(q_expected, q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        #TODO update target network\n",
        "        #TODO undestand the different between the local and the target network\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_network.parameters(), self.network.parameters()):\n",
        "            target_param.data.copy_(local_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_progress(scores, window_size=50):\n",
        "    \"\"\"\n",
        "    Plot the training progress of a DQN agent\n",
        "\n",
        "    Args:\n",
        "        scores (list): List of scores from each episode\n",
        "        window_size (int): Size of the moving average window\n",
        "    \"\"\"\n",
        "    # Convert to numpy array for easier manipulation\n",
        "    scores = np.array(scores)\n",
        "\n",
        "    # Calculate moving average\n",
        "    moving_averages = []\n",
        "    for i in range(len(scores)):\n",
        "        if i < window_size:\n",
        "            moving_averages.append(np.mean(scores[:i+1]))\n",
        "        else:\n",
        "            moving_averages.append(np.mean(scores[i-window_size+1:i+1]))\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(scores, label='Score', alpha=0.3, color='blue')\n",
        "    plt.plot(moving_averages, label=f'{window_size}-episode Moving Average',\n",
        "             color='red', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('DQN Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add horizontal line at score 200 (solving threshold)\n",
        "    plt.axhline(y=200, color='green', linestyle='--', alpha=0.5,\n",
        "                label='Solving Threshold')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  MAIN TRAINING LOOP (Static Method)\n",
        "# ==========================================\n",
        "def run_training(env, agent, config, preprocess_observation, print_every=10):\n",
        "        \"\"\"\n",
        "        Run the main training loop. Hyperparameters (total_episodes, epsilon, frame_skipping, etc.) are read from config.\n",
        "        \"\"\"\n",
        "        total_steps = 0\n",
        "        epsilon = config.epsilon\n",
        "        print(f\"Starting training: {config.total_episodes} episodes, epsilon={epsilon:.3f} -> {config.epsilon_ending_value:.3f}\")\n",
        "        print(\"-\" * 60)\n",
        "        for episode in range(config.total_episodes):\n",
        "            obs, info = env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "            episode_steps = 0\n",
        "            while not done: #TODO check if max steps is used or not\n",
        "                #TODO check if preprocess is neede or is it already done in the step function\n",
        "                state = preprocess_observation(obs)\n",
        "                action = agent.select_action(state, epsilon)\n",
        "                next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "                done = terminated or truncated\n",
        "                episode_reward += reward\n",
        "                episode_steps += 1\n",
        "\n",
        "                #TODO handle score history for plotting\n",
        "\n",
        "                next_state = preprocess_observation(next_obs)\n",
        "                #TODO handel memory size\n",
        "                agent.memory.push((state, action, reward, next_state, done))\n",
        "\n",
        "                epsilon = max(config.epsilon_ending_value, config.epsilon_decay_value * epsilon)\n",
        "\n",
        "                # Update policy with frame skipping: train every `frame_skipping` env steps\n",
        "                if total_steps % config.frame_skipping == 0:\n",
        "                    agent.train_step(config)\n",
        "\n",
        "                total_steps += 1\n",
        "                #TODO check if need to update target network\n",
        "                obs = next_obs\n",
        "\n",
        "            if (episode + 1) % print_every == 0 or episode == 0:\n",
        "                print(f\"Episode {episode + 1:5d}/{config.total_episodes} | reward: {episode_reward:7.2f} | steps: {episode_steps:4d} | epsilon: {epsilon:.3f} | total_steps: {total_steps}\")\n",
        "        print(\"-\" * 60)\n",
        "        print(\"Training finished.\")\n",
        "                    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training: 1000 episodes, epsilon=1.000 -> 0.010\n",
            "------------------------------------------------------------\n",
            "Episode     1/1000 | reward:    0.00 | steps:  100 | epsilon: 0.606 | total_steps: 100\n",
            "Episode    10/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 1000\n",
            "Episode    20/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 2000\n",
            "Episode    30/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 3000\n",
            "Episode    40/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 4000\n",
            "Episode    50/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 5000\n",
            "Episode    60/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 6000\n",
            "Episode    70/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 7000\n",
            "Episode    80/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 8000\n",
            "Episode    90/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 9000\n",
            "Episode   100/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 10000\n",
            "Episode   110/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 11000\n",
            "Episode   120/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 12000\n",
            "Episode   130/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 13000\n",
            "Episode   140/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 14000\n",
            "Episode   150/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 15000\n",
            "Episode   160/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 16000\n",
            "Episode   170/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 17000\n",
            "Episode   180/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 18000\n",
            "Episode   190/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 19000\n",
            "Episode   200/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 20000\n",
            "Episode   210/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 21000\n",
            "Episode   220/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 22000\n",
            "Episode   230/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 23000\n",
            "Episode   240/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 24000\n",
            "Episode   250/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 25000\n",
            "Episode   260/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 26000\n",
            "Episode   270/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 27000\n",
            "Episode   280/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 28000\n",
            "Episode   290/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 29000\n",
            "Episode   300/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 30000\n",
            "Episode   310/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 31000\n",
            "Episode   320/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 32000\n",
            "Episode   330/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 33000\n",
            "Episode   340/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 34000\n",
            "Episode   350/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 35000\n",
            "Episode   360/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 36000\n",
            "Episode   370/1000 | reward:    0.00 | steps:  100 | epsilon: 0.010 | total_steps: 37000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m preprocess_observation \u001b[38;5;241m=\u001b[39m pre_process\n\u001b[1;32m     14\u001b[0m agent \u001b[38;5;241m=\u001b[39m Agent(config)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_observation\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[28], line 21\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(env, agent, config, preprocess_observation, print_every)\u001b[0m\n\u001b[1;32m     19\u001b[0m state \u001b[38;5;241m=\u001b[39m preprocess_observation(obs)\n\u001b[1;32m     20\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mselect_action(state, epsilon)\n\u001b[0;32m---> 21\u001b[0m next_obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     23\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
            "Cell \u001b[0;32mIn[5], line 193\u001b[0m, in \u001b[0;36mKeyDoorBallEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    190\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m, reward, terminated, truncated, info\n",
            "Cell \u001b[0;32mIn[5], line 78\u001b[0m, in \u001b[0;36mKeyDoorBallEnv._get_obs\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the current observation after applying preprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(obs)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/minigrid/minigrid_env.py:739\u001b[0m, in \u001b[0;36mMiniGridEnv.get_frame\u001b[0;34m(self, highlight, tile_size, agent_pov)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pov_render(tile_size)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_full_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/minigrid/minigrid_env.py:707\u001b[0m, in \u001b[0;36mMiniGridEnv.get_full_render\u001b[0;34m(self, highlight, tile_size)\u001b[0m\n\u001b[1;32m    704\u001b[0m         highlight_mask[abs_i, abs_j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# Render the whole grid\u001b[39;00m\n\u001b[0;32m--> 707\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhighlight_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhighlight_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/minigrid/core/grid.py:240\u001b[0m, in \u001b[0;36mGrid.render\u001b[0;34m(self, tile_size, agent_pos, agent_dir, highlight_mask)\u001b[0m\n\u001b[1;32m    238\u001b[0m         xmin \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m tile_size\n\u001b[1;32m    239\u001b[0m         xmax \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m tile_size\n\u001b[0;32m--> 240\u001b[0m         \u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mymin\u001b[49m\u001b[43m:\u001b[49m\u001b[43mymax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxmin\u001b[49m\u001b[43m:\u001b[49m\u001b[43mxmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m tile_img\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# run the training loop (hyperparameters passed via config)\n",
        "config = Config(\n",
        "    env=env,\n",
        "    memory_size=1,\n",
        "    minibatch_size=1,\n",
        "    discount_factor=0.99,\n",
        "    total_episodes=1000,\n",
        "    epsilon=1.0,\n",
        "    epsilon_ending_value=0.01,\n",
        "    epsilon_decay_value=0.995,\n",
        "    frame_skipping=1\n",
        ")\n",
        "preprocess_observation = pre_process\n",
        "agent = Agent(config)\n",
        "run_training(env, agent, config, preprocess_observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LilachPardess/final-rl-project-minigrid/blob/main/Final_Project_RL_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# üéÆ Deep RL Final Project ‚Äî MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## üåç The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8√ó8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key ‚Üí Open door ‚Üí Pick up ball ‚Üí Reach goal |\n",
        "\n",
        "## ‚úÖ What You CAN Modify\n",
        "- **Preprocessing** ‚Äî Implement your own observation preprocessing function.\n",
        "- **Reward shaping** ‚Äî Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** ‚Äî Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## ‚ùå What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## üì¶ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## üß™ Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## üßæ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!sudo apt-get update\n",
        "#!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "!pip install imageio\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gymnasium\n",
        "!pip install minigrid\n",
        "!pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)\n",
        "\n",
        "# Xvfb is Linux-only (e.g. Colab). On macOS, skip virtual display.\n",
        "import sys\n",
        "if sys.platform == \"linux\":\n",
        "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "else:\n",
        "    display = None  # macOS: use default display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> ‚ö†Ô∏è **Important**\n",
        ">\n",
        "> The two environments below are **fixed**‚Äîdo not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** ‚Äî set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** ‚Äî edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = -0.001\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë  ‚úÖ STUDENT TODO: Update observation_space to match preprocessing   ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 3),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "        # ‚ïë                     END OF EDITABLE SECTION                         ‚ïë\n",
        "        # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: Core environment methods below                       ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚úÖ STUDENT TODO: Modify reward shaping below                           ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        üí° You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë                     END OF EDITABLE SECTION                             ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "    # ‚ïë  ‚õî DO NOT MODIFY: State getter methods (use these in reward shaping)   ‚ïë\n",
        "    # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> üí° **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320√ó320√ó3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Ensure opencv-python is installed in the current kernel (run once, then re-run cell if import fails)\n",
        "import subprocess, sys\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"-q\"])\n",
        "\n",
        "import cv2\n",
        "\n",
        "# Example Preprocessing Function\n",
        "PREPROCESS_SIZE = (84, 84)  # (height, width) ‚Äî smaller = faster training, less memory\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment.\n",
        "    1. Copy to array\n",
        "    2. Resize to smaller dimensions (e.g. 84x84) for faster training and less replay memory.\n",
        "    3. Normalize pixel values to [0, 1] (divide by 255) for stable neural network training.\n",
        "\n",
        "    Input:  RGB image (320, 320, 3), uint8 [0, 255]\n",
        "    Output: RGB image (84, 84, 3), float32 [0.0, 1.0]\n",
        "    \"\"\"\n",
        "    arr = np.array(img, copy=True)\n",
        "    resized = cv2.resize(arr, (PREPROCESS_SIZE[1], PREPROCESS_SIZE[0]), interpolation=cv2.INTER_AREA)\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "\n",
        "    #TODO check if check use several images\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# üîç Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8√ó8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    3\n",
            "Agent position:     (2, 5)\n",
            "Goal position:      (8, 8)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key ‚Üí Door ‚Üí Ball ‚Üí Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8√ó8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key ‚Üí Open door ‚Üí Enter right room ‚Üí Pick up ball ‚Üí Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` ‚Äî True if agent has the key\n",
        "- `is_carrying_ball()` ‚Äî True if agent has the ball\n",
        "- `is_door_open()` ‚Äî True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0.0, 1.0, (84, 84, 3), float32)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (84, 84, 3)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(1), np.int64(8))\n",
            "Carrying key:    True\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <video width=\"640\" height=\"480\" controls>\n",
              "    <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "  </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "video_filename = \"KeyDoorBallEnv_random.mp4\"\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "embed_mp4(video_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Your Code Below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"Select best available device: CUDA > MPS (Apple Silicon) > CPU.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda:0\")\n",
        "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\")  # Apple Silicon GPU\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "# ==========================================\n",
        "# Config (hyperparameters and env-derived settings)\n",
        "# ==========================================\n",
        "class Config:\n",
        "    \"\"\"Holds agent/environment config. Pass env to fill input_shape and num_actions from it.\"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env=None,\n",
        "        memory_size=10_000,\n",
        "        minibatch_size=64,\n",
        "        discount_factor=0.99,\n",
        "        total_episodes=1000,\n",
        "        epsilon=1.0,\n",
        "        epsilon_ending_value=0.01,\n",
        "        epsilon_decay_value=0.995,\n",
        "        frame_skipping=1,\n",
        "        target_network_update_frequency=1000,\n",
        "        **kwargs\n",
        "    ):\n",
        "        obs_space = env.observation_space\n",
        "        raw_shape = getattr(obs_space, \"shape\", (3, 84, 84))\n",
        "        # PyTorch Conv2d expects (C, H, W). If env gives (H, W, C), convert.\n",
        "        if len(raw_shape) == 3 and raw_shape[-1] in (1, 3):\n",
        "            self.input_shape = (raw_shape[-1], raw_shape[0], raw_shape[1])\n",
        "        else:\n",
        "            self.input_shape = raw_shape\n",
        "            self.num_actions = env.action_space.n\n",
        "        self.memory_size = memory_size\n",
        "        self.minibatch_size = minibatch_size\n",
        "        self.discount_factor = discount_factor\n",
        "        # Training loop hyperparameters\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_ending_value = epsilon_ending_value\n",
        "        self.epsilon_decay_value = epsilon_decay_value\n",
        "        self.frame_skipping = frame_skipping\n",
        "        self.num_actions = env.action_space.n\n",
        "        self.target_network_update_frequency = target_network_update_frequency\n",
        "# ==========================================\n",
        "# The Model\n",
        "# ==========================================\n",
        "class MiniGridNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_actions):\n",
        "            super().__init__()\n",
        "            c, h, w = input_shape\n",
        "\n",
        "            # 1. Define the Feature Extractor\n",
        "            self.feature_extractor = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=c, out_channels=16, kernel_size=8, stride=4),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2),\n",
        "                nn.ReLU(),\n",
        "                nn.Flatten(),\n",
        "            )\n",
        "\n",
        "            # 2. Define the Q-Head\n",
        "            self.q_head = nn.Sequential(\n",
        "                nn.Linear(2592, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(512, num_actions)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(self._to_chw(x))\n",
        "        return self.q_head(features)\n",
        "\n",
        "    def _to_chw(self, x):\n",
        "        # If the last dimension is 1 or 3, it's definitely HWC. Move C to the front.\n",
        "        if x.shape[-1] in (1, 3):\n",
        "            if x.dim() == 3: # Single observation (H, W, C)\n",
        "                return x.permute(2, 0, 1).unsqueeze(0)\n",
        "            elif x.dim() == 4: # Batch (N, H, W, C)\n",
        "                return x.permute(0, 3, 1, 2)\n",
        "        # If it's already (N, C, H, W), just return it\n",
        "        return x\n",
        "\n",
        "# ==========================================\n",
        "# THE MEMORY\n",
        "# ==========================================\n",
        "class ExperienceMemory:\n",
        "    def __init__(self, capacity, is_on_policy=False):\n",
        "        # Use GPU if available (CUDA or MPS for Apple Silicon), otherwise CPU\n",
        "        self.device = get_device()\n",
        "        # Set the maximum memory capacity\n",
        "        self.capacity = capacity\n",
        "        # Initialize the memory as a list\n",
        "        self.memory = []\n",
        "\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        # Randomly sample a batch of experiences\n",
        "        experiences = random.sample(self.memory, k=batch_size)\n",
        "\n",
        "        # Extract each part of the experience tuple (state, action, reward, next_state, done)\n",
        "        states = torch.from_numpy(np.stack([e[0] for e in experiences])).float().to(self.device)\n",
        "        next_states = torch.from_numpy(np.stack([e[3] for e in experiences])).float().to(self.device)\n",
        "\n",
        "        actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long().to(self.device)\n",
        "        rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float().to(self.device)\n",
        "        dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float().to(self.device)\n",
        "\n",
        "        actions = actions.view(-1, 1)\n",
        "        return states, next_states, actions, rewards, dones\n",
        "\n",
        "    def push(self, experience):\n",
        "        # Add the new experience to memory\n",
        "        self.memory.append(experience)\n",
        "\n",
        "        # If memory exceeds the capacity, remove the oldest experience\n",
        "        if len(self.memory) > self.capacity:\n",
        "            self.memory.pop(0)  # Remove the first item (FIFO - First In, First Out)\n",
        "    \n",
        "    \n",
        "# ==========================================\n",
        "# THE AGENT (The Logic)\n",
        "# ==========================================\n",
        "class Agent:\n",
        "    def __init__(self, config):\n",
        "        self.device = get_device()  # CUDA GPU > MPS (Apple Silicon) > CPU\n",
        "        self.network = MiniGridNet(config.input_shape, config.num_actions).to(self.device)\n",
        "        self.target_network = copy.deepcopy(self.network)\n",
        "        self.optimizer = optim.Adam(self.network.parameters(), lr=1e-4)\n",
        "        self.memory = ExperienceMemory(config.memory_size)\n",
        "        self.minibatch_size = config.minibatch_size\n",
        "        self.num_actions = config.num_actions\n",
        "        self.learn_step_counter = 0\n",
        "\n",
        "    def select_action(self, state, epsilon):\n",
        "        if random.random() < epsilon:\n",
        "            return random.randint(0, self.num_actions - 1)\n",
        "        with torch.no_grad():\n",
        "            state = torch.tensor(state, dtype=torch.float32)\n",
        "            state = state.to(self.device)\n",
        "            q_values = self.network(state)\n",
        "            return q_values.argmax(dim=1).item()\n",
        "\n",
        "    def train_step(self, config):\n",
        "            states, next_states, actions, rewards, dones = self.memory.sample(self.minibatch_size)\n",
        "\n",
        "            next_q_targets = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "            q_targets = rewards + (config.discount_factor * next_q_targets * (1 - dones))\n",
        "            q_expected = self.network(states).gather(1, actions.to(self.device))\n",
        "\n",
        "            loss = F.mse_loss(q_expected, q_targets)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            self.learn_step_counter += 1\n",
        "            if self.learn_step_counter % config.target_network_update_frequency == 0: # Update every 1000 steps\n",
        "                self.update_target_network()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        for target_param, local_param in zip(self.target_network.parameters(), self.network.parameters()):\n",
        "            target_param.data.copy_(local_param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: mps\n",
            "GPU: Apple Silicon (MPS)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell anytime to see if you're on CPU or GPU (run after the cell that defines get_device)\n",
        "device = get_device()\n",
        "print(\"Running on:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "elif device.type == \"mps\":\n",
        "    print(\"GPU: Apple Silicon (MPS)\")\n",
        "else:\n",
        "    print(\"GPU: None (CPU only)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_training_setup(env, config, agent):\n",
        "    \"\"\"Print important config, agent, and network parameters before training.\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"CONFIG\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  env:                  {env.spec.id if env.spec else type(env).__name__}\")\n",
        "    print(f\"  observation shape:   {config.input_shape} (C, H, W)\")\n",
        "    print(f\"  num_actions:         {config.num_actions}\")\n",
        "    print(f\"  memory_size:         {config.memory_size}\")\n",
        "    print(f\"  minibatch_size:      {config.minibatch_size}\")\n",
        "    print(f\"  discount_factor:     {config.discount_factor}\")\n",
        "    print(f\"  total_episodes:      {config.total_episodes}\")\n",
        "    print(f\"  epsilon:             {config.epsilon} -> {config.epsilon_ending_value} (decay {config.epsilon_decay_value})\")\n",
        "    print(f\"  frame_skipping:      {config.frame_skipping}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"AGENT / NETWORK\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"  device:              {agent.device}\")\n",
        "    n_params = sum(p.numel() for p in agent.network.parameters())\n",
        "    print(f\"  network parameters:  {n_params:,}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Window size for rolling average (last N episodes)\n",
        "LAST_EPISODES = 300\n",
        "scores_on_last_windowSize_episodes = deque(maxlen=LAST_EPISODES)\n",
        "\n",
        "\n",
        "def plot_training_progress(scores, window_size=50, solving_threshold=None):\n",
        "    \"\"\"\n",
        "    Plot the training progress of a DQN agent.\n",
        "\n",
        "    Args:\n",
        "        scores (list): List of scores from each episode\n",
        "        window_size (int): Size of the moving average window\n",
        "        solving_threshold (float, optional): If set, draw a horizontal line at this score.\n",
        "                                             For MiniGrid use e.g. 1.0 or None to omit.\n",
        "    \"\"\"\n",
        "    scores = np.array(scores)\n",
        "\n",
        "    moving_averages = []\n",
        "    for i in range(len(scores)):\n",
        "        if i < window_size:\n",
        "            moving_averages.append(np.mean(scores[:i+1]))\n",
        "        else:\n",
        "            moving_averages.append(np.mean(scores[i-window_size+1:i+1]))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(scores, label='Score', alpha=0.3, color='blue')\n",
        "    plt.plot(moving_averages, label=f'{window_size}-episode Moving Average',\n",
        "             color='red', linewidth=2)\n",
        "\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('DQN Training Progress')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    if solving_threshold is not None:\n",
        "        plt.axhline(y=solving_threshold, color='green', linestyle='--', alpha=0.5,\n",
        "                    label='Solving Threshold')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "#  MAIN TRAINING LOOP (Static Method)\n",
        "# ==========================================\n",
        "\n",
        "def _print_training_progress(episode, avg_score, epsilon, print_every, is_solved=False, solved_episode=None):\n",
        "    \"\"\"Print training progress. Called each episode.\"\"\"\n",
        "    print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpsilon: {:.4f}'.format(\n",
        "        episode + 1, avg_score, epsilon), end=\"\")\n",
        "    if (episode + 1) % print_every == 0:\n",
        "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tEpsilon: {:.4f}'.format(\n",
        "            episode + 1, avg_score, epsilon))\n",
        "    if is_solved and solved_episode is not None:\n",
        "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(\n",
        "            solved_episode, avg_score))\n",
        "\n",
        "\n",
        "def run_training(env, agent, config, print_every=100,\n",
        "                 solving_threshold=None, checkpoint_path='checkpoint.pth'):\n",
        "    \"\"\"\n",
        "    Run the main training loop. Returns scores_history for plotting.\n",
        "    Hyperparameters (total_episodes, epsilon, frame_skipping, etc.) are read from config.\n",
        "    \"\"\"\n",
        "    total_steps = 0\n",
        "    epsilon = config.epsilon\n",
        "\n",
        "    scores_history = []\n",
        "    scores_window = deque(maxlen=LAST_EPISODES)\n",
        "    print(f\"Starting training: {config.total_episodes} episodes, epsilon={epsilon:.3f} -> {config.epsilon_ending_value:.3f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    \n",
        "    for episode in range(config.total_episodes):\n",
        "        obs, info = env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        episode_steps = 0\n",
        "        while not done:\n",
        "            action = agent.select_action(obs, epsilon)\n",
        "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            episode_reward += reward\n",
        "            episode_steps += 1\n",
        "\n",
        "            agent.memory.push((obs, action, reward, next_obs, done))\n",
        "\n",
        "            if total_steps > config.minibatch_size and total_steps % config.frame_skipping == 0:\n",
        "                agent.train_step(config)\n",
        "\n",
        "            total_steps += 1\n",
        "            obs = next_obs\n",
        "        \n",
        "        epsilon = max(config.epsilon_ending_value, config.epsilon_decay_value * epsilon)\n",
        "\n",
        "        scores_history.append(episode_reward)\n",
        "        scores_window.append(episode_reward)\n",
        "\n",
        "        avg_score = np.mean(scores_window)\n",
        "        is_solved = (solving_threshold is not None and len(scores_window) == LAST_EPISODES\n",
        "                     and avg_score >= solving_threshold)\n",
        "        _print_training_progress(episode, avg_score, epsilon, print_every,\n",
        "                                 is_solved=is_solved,\n",
        "                                 solved_episode=episode + 1 - LAST_EPISODES if is_solved else None)\n",
        "\n",
        "        if is_solved:\n",
        "            torch.save(agent.network.state_dict(), checkpoint_path)\n",
        "            break\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "    print(\"Training finished.\")\n",
        "    return scores_history\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CONFIG\n",
            "==================================================\n",
            "  env:                  SimpleGridEnv\n",
            "  observation shape:   (3, 84, 84) (C, H, W)\n",
            "  num_actions:         3\n",
            "  memory_size:         10000\n",
            "  minibatch_size:      64\n",
            "  discount_factor:     0.99\n",
            "  total_episodes:      1000\n",
            "  epsilon:             1.0 -> 0.01 (decay 0.995)\n",
            "  frame_skipping:      1\n",
            "==================================================\n",
            "AGENT / NETWORK\n",
            "==================================================\n",
            "  device:              mps\n",
            "  network parameters:  1,340,467\n",
            "==================================================\n",
            "Starting training: 1000 episodes, epsilon=1.000 -> 0.010\n",
            "------------------------------------------------------------\n",
            "Episode 1\tAverage Score: -0.50\tEpsilon: 0.9950State is not a tensor: <class 'numpy.ndarray'>\n",
            "State is not a tensor: <class 'numpy.ndarray'>\n",
            "State is not a tensor: <class 'numpy.ndarray'>\n",
            "State is not a tensor: <class 'numpy.ndarray'>\n",
            "Episode 2\tAverage Score: -0.50\tEpsilon: 0.9900"
          ]
        }
      ],
      "source": [
        "current_env = SimpleGridEnv(max_steps=500, preprocess=pre_process)\n",
        "# run the training loop (hyperparameters passed via config)\n",
        "config = Config(\n",
        "    env=current_env,\n",
        "    memory_size=10000,\n",
        "    minibatch_size=64,\n",
        "    discount_factor=0.99,\n",
        "    total_episodes=1000,\n",
        "    epsilon=1.0,\n",
        "    epsilon_ending_value=0.01,\n",
        "    epsilon_decay_value=0.995,\n",
        "    frame_skipping=1\n",
        ")\n",
        "agent = Agent(config)\n",
        "\n",
        "print_training_setup(current_env, config, agent)\n",
        "\n",
        "# Run training and collect scores for plotting (solving_threshold=None for MiniGrid; set e.g. 1.0 to stop early)\n",
        "scores_history = run_training(current_env, agent, config, print_every=100,\n",
        "                               solving_threshold=None, checkpoint_path='checkpoint.pth')\n",
        "\n",
        "# Plot training progress (solving_threshold=None omits the green line; set e.g. 200 for CartPole-style)\n",
        "plot_training_progress(scores_history, window_size=50, solving_threshold=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
